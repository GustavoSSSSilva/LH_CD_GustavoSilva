{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5ba88c-2da5-4fc8-bd65-b769874d3c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro Quadrático Médio (MSE): 0.0462\n",
      "Coeficiente de Determinação (R²): 0.4347\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Carregar o dataset\n",
    "df = pd.read_csv('desafio_indicium_imdb.csv')\n",
    "\n",
    "# Remover linhas com valores ausentes nas colunas-chave e remover duplicatas\n",
    "df.dropna(subset=['IMDB_Rating', 'Genre', 'Director', 'Gross', 'No_of_Votes', 'Meta_score'], inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# 1. Selecionar as variáveis (features) e o alvo (target)\n",
    "features = ['Genre', 'Director', 'Gross', 'No_of_Votes', 'Meta_score']\n",
    "target = 'IMDB_Rating'\n",
    "\n",
    "# Usar .loc para evitar o SettingWithCopyWarning\n",
    "X = df.loc[:, features].copy()\n",
    "y = df.loc[:, target].copy()\n",
    "\n",
    "# 2. Pré-processamento e Transformação das Variáveis\n",
    "# Lidar com os valores de Gross de forma segura\n",
    "X['Gross'] = X['Gross'].apply(lambda x: float(x.replace(',', '')) if isinstance(x, str) else x)\n",
    "X.loc[:, 'Gross_log'] = np.log1p(X['Gross'])\n",
    "\n",
    "# Transformar variáveis categóricas\n",
    "X.loc[:, 'Genre_main'] = X['Genre'].apply(lambda x: x.split(',')[0].strip())\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Genre_main', 'Director']),\n",
    "        ('num', StandardScaler(), ['Gross_log', 'No_of_Votes', 'Meta_score'])\n",
    "    ])\n",
    "\n",
    "# 3. Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Criar e treinar o modelo de Regressão\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5. Fazer previsões e avaliar o modelo\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse:.4f}\")\n",
    "print(f\"Coeficiente de Determinação (R²): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd3a3b0f-c0d6-4f69-aca5-8b23d31c6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modelo_preditivo_imdb.pkl', 'wb') as file:\n",
    "    pickle.dump(model_pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc2847-65e4-419d-98dd-a789f1f1f0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
